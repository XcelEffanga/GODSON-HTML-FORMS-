<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
</head>

<body>
    CSC 242

    1a. Data Structures
    Definition: A data structure is a way of organizing and storing data in a computer so that it can be accessed and
    modified efficiently.
    Purpose:
    • Efficient Data Access and Manipulation: Data structures enable efficient data retrieval, insertion, deletion, and
    updating.
    • Memory Management: Data structures help in managing and optimizing the use of memory.
    • Organizing Data: They provide a way to organize data logically and hierarchically.
    • Data Abstraction: Data structures provide a means to represent complex relationships and interactions within data.
    1b. Descriptions and Real-Life Analogies
    I. Structure and Structuring
    • Structure: An organized arrangement of components that define the configuration or organization of a system.
    o Analogy: Think of a bookshelf. The structure of the bookshelf includes the shelves, frame, and supports, which are
    arranged to hold books in an organized manner.
    • Structuring: The process of arranging or organizing components into a structure.
    o Analogy: The act of assembling the bookshelf. This includes putting together the shelves, frame, and supports in a
    way that results in a stable and functional bookshelf.
    II. Abstract Data Types (ADT)
    • Definition: A model for data types where data and operations are defined independently of their implementation.
    o Analogy: A coffee machine. The coffee machine provides an interface (buttons) for users to select and receive
    coffee (operations), but users do not need to know the internal workings of the machine (implementation).
    III. Primitive Data Types
    • Definition: Basic data types provided by a programming language as building blocks, typically representing single
    values.
    o Analogy: Basic ingredients in cooking, like salt, sugar, and flour. These ingredients (data types) are fundamental
    and can be combined to create more complex dishes (complex data types and structures).
    2a. Tree Traversal
    • Definition: The process of visiting each node in a tree data structure, exactly once, in a systematic way.
    2b. Tree Traversal Methods and Applications
    1. In-order Traversal: Visit the left subtree, then the root node, and finally the right subtree.
    o Application: Used in binary search trees to retrieve nodes in ascending order.
    2. Pre-order Traversal: Visit the root node first, then the left subtree, followed by the right subtree.
    o Application: Used to create a copy of the tree or for prefix notation in arithmetic expressions.
    3. Post-order Traversal: Visit the left subtree, then the right subtree, and finally the root node.
    o Application: Used to delete a tree or evaluate postfix notation in arithmetic expressions.
    2c. In-order Traversal Example
    Given a simple binary tree:
    markdown
    Copy code
    4
    / \
    2 6
    / \ / \
    1 3 5 7
    In-order traversal steps:
    1. Visit left subtree of 4 (root):
    o Visit left subtree of 2:
     Visit 1 (leftmost node).
    o Visit 2.
    o Visit right subtree of 2:
     Visit 3.
    2. Visit 4 (root).
    3. Visit right subtree of 4:
    o Visit left subtree of 6:
     Visit 5.
    o Visit 6.
    o Visit right subtree of 6:
     Visit 7.
    Result: 1, 2, 3, 4, 5, 6, 7
    3a. Running Time of an Algorithm
    • Definition: The amount of time an algorithm takes to complete as a function of the size of its input.
    3b. Deriving Running Time
    Code:
    python
    for i = 1 to n
    print j
    • The loop runs from i = 1 to i = n, which means it executes n times.
    • The statement print j is executed once for each iteration.
    • Running Time: O(n) because the time complexity is directly proportional to the number of iterations n.
    3c. Proving Merge Sort vs. Selection Sort
    Merge Sort:
    • Time Complexity: O(n log n)
    • Explanation: Merge Sort divides the array into halves and sorts them recursively, resulting in a logarithmic
    division and linear merging.
    Selection Sort:
    • Time Complexity: O(n^2)
    • Explanation: Selection Sort repeatedly finds the minimum element and moves it to the front, resulting in quadratic
    time complexity due to nested loops.
    Proof:
    • Example: For an array of size 10000:
    o Merge Sort: 10000 * log(10000) ≈ 10000 * 4 ≈ 40000 operations.
    o Selection Sort: 10000^2 = 100000000 operations.
    Comparison: 100000000 / 40000 = 2500, showing that Merge Sort is significantly more efficient, by a factor of at
    least 100 times.
    4a. Definitions
    • Time Complexity: Measures the amount of computational time an algorithm takes relative to the input size.
    • Space Complexity: Measures the amount of memory space an algorithm uses relative to the input size.
    • Algorithm: A step-by-step procedure or formula for solving a problem.
    4b. Time and Space Tradeoff in Algorithm Design
    • Explanation: Optimizing algorithms often involves a tradeoff between time and space. Faster algorithms may use
    more memory (space), while memory-efficient algorithms may take longer to execute (time).
    4c. Binary Search Algorithm for Searching '22'
    Given array:
    Copy code
    12, 5, 68, 11, 15, 16, 18, 22, 30
    1. Sort the array: 5, 11, 12, 15, 16, 18, 22, 30, 68
    2. Binary Search Steps:
    o Start with the middle element: 16 (index 4).
    o 22 > 16, search in the right half: 18, 22, 30, 68.
    o Middle element of right half: 22 (index 6).
    o 22 == 22, found the element at index 6.
    5a. Searching Algorithms
    1. Linear Search: Sequentially checks each element of the list until the target element is found or the list ends.
    o Example: Finding a specific name in an unsorted list of names.
    2. Binary Search: Divides the sorted list into halves to find the target element.
    o Example: Searching for a number in a sorted array of integers.
    3. Hash Table Search: Uses a hash function to compute the index into an array of buckets, from which the desired
    value can be found.
    o Example: Looking up a value based on a key in a dictionary.
    5b. Quicksort
    Given array:
    Copy code
    12, 19, -5, 4, 20, 48, 1, 6
    1. Choose a pivot: 12.
    2. Partition the array:
    o Less than pivot: -5, 4, 1, 6.
    o Pivot: 12.
    o Greater than pivot: 19, 20, 48.
    Result after first partition:
    diff
    Copy code
    -5, 4, 1, 6, 12, 19, 20, 48
    Repeat the process recursively on the left and right sub-arrays until fully sorted.
    5c. Mergesort
    Given array:
    Copy code
    12, 19, -5, 4, 20, 48, 1, 6
    1. Divide the array into two halves: [12, 19, -5, 4] and [20, 48, 1, 6].
    2. Recursively divide each half until each sub-array contains a single element.
    3. Merge the sub-arrays in a sorted manner.
    Result after merging:
    diff
    Copy code
    -5, 1, 4, 6, 12, 19, 20, 48
    Diagram for Quicksort and Mergesort
    Quicksort:
    yaml
    Copy code
    Initial array: [12, 19, -5, 4, 20, 48, 1, 6]
    Choose pivot: 12

    Partitioned:
    Less than pivot: [-5, 4, 1, 6]
    Pivot: [12]
    Greater than pivot: [19, 20, 48]

    Continue recursively:
    Left part: [-5, 4, 1, 6]
    Pivot: 4
    Partitioned: [-5, 1] [4] [6]

    Right part: [19, 20, 48]
    Pivot: 20
    Partitioned: [19] [20] [48]

    Result: [-5, 1, 4, 6, 12, 19, 20, 48]
    Mergesort:
    sql
    Copy code
    Initial array: [12, 19, -5, 4, 20, 48, 1, 6]

    Divide:
    Left: [12, 19, -5, 4]
    Right: [20, 48, 1,


</body>

</html>